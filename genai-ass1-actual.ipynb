{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1111749,"sourceType":"datasetVersion","datasetId":623329}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pickle\nimport torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nfrom tqdm import tqdm\n\n\ndef find_image_dir():\n    base_input = '/kaggle/input/datasets/adityajn105/flickr30k/Images'\n    \n    for root, dirs, files in os.walk(base_input):\n        if len([f for f in files if f.endswith('.jpg')]) > 1000:\n            return root\n    return None\n\n\nclass FlickrDataset(Dataset):\n   \n    def __init__(self, img_dir, transform):\n        self.img_names = [f for f in os.listdir(img_dir) if f.endswith(('.jpg', '.jpeg'))]\n        self.transform = transform\n        self.img_dir = img_dir\n    \n    def __len__(self):\n        return len(self.img_names)\n    \n    def __getitem__(self, idx):\n        name = self.img_names[idx]\n        img_path = os.path.join(self.img_dir, name)\n        img = Image.open(img_path).convert('RGB')\n        return self.transform(img), name\n\n\ndef main():\n    IMAGE_DIR = find_image_dir()\n    OUTPUT_FILE = '/kaggle/working/flickr30k_features.pkl'\n    \n    if IMAGE_DIR:\n        print(f\"✓ Found images at: {IMAGE_DIR}\")\n    else:\n        raise FileNotFoundError(\n            \"Could not find the Flickr30k image directory. \"\n            \"Please ensure the dataset is added to the notebook.\"\n        )\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    \n    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n    model = nn.Sequential(*list(model.children())[:-1])\n    model = nn.DataParallel(model).to(device)\n    model.eval()\n    \n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ])\n    \n    dataset = FlickrDataset(IMAGE_DIR, transform)\n    loader = DataLoader(dataset, batch_size=128, num_workers=4, pin_memory=True)\n    \n    print(f\"Total images to process: {len(dataset)}\")\n    \n    features_dict = {}\n    with torch.no_grad():\n        for imgs, names in tqdm(loader, desc=\"Extracting Features\"):\n            feats = model(imgs.to(device)).view(imgs.size(0), -1)\n            \n            for i, name in enumerate(names):\n                features_dict[name] = feats[i].cpu().numpy()\n    \n    with open(OUTPUT_FILE, 'wb') as f:\n        pickle.dump(features_dict, f)\n    \n    print(f\"\\n✓ Success! {len(features_dict)} images processed\")\n    print(f\"✓ Features saved to {OUTPUT_FILE}\")\n    print(f\"✓ Feature shape: {list(features_dict.values())[0].shape}\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:06:01.489689Z","iopub.execute_input":"2026-02-15T11:06:01.490273Z","iopub.status.idle":"2026-02-15T11:08:52.791294Z","shell.execute_reply.started":"2026-02-15T11:06:01.490245Z","shell.execute_reply":"2026-02-15T11:08:52.790407Z"}},"outputs":[{"name":"stdout","text":"✓ Found images at: /kaggle/input/datasets/adityajn105/flickr30k/Images\nUsing device: cuda\nDownloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 97.8M/97.8M [00:00<00:00, 209MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Total images to process: 31783\n","output_type":"stream"},{"name":"stderr","text":"Extracting Features: 100%|██████████| 249/249 [01:52<00:00,  2.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ Success! 31783 images processed\n✓ Features saved to /kaggle/working/flickr30k_features.pkl\n✓ Feature shape: (2048,)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nimport os\nimport pickle\nimport pandas as pd\nimport numpy as np\nfrom collections import Counter\nimport re\n\n\ndef find_captions_file():\n   \n    base_input = '/kaggle/input/datasets/adityajn105/flickr30k'\n    \n    for root, dirs, files in os.walk(base_input):\n        if 'captions.txt' in files:\n            return os.path.join(root, 'captions.txt')\n    return None\n\n\nclass Vocabulary:\n    \n    def __init__(self, freq_threshold=5):\n        self.freq_threshold = freq_threshold\n        self.word2idx = {}\n        self.idx2word = {}\n        self.word_freq = Counter()\n        \n        self.pad_token = \"<pad>\"\n        self.start_token = \"<start>\"\n        self.end_token = \"<end>\"\n        self.unk_token = \"<unk>\"\n        \n        self.word2idx = {\n            self.pad_token: 0,\n            self.start_token: 1,\n            self.end_token: 2,\n            self.unk_token: 3\n        }\n        self.idx2word = {v: k for k, v in self.word2idx.items()}\n        self.idx = 4\n    \n    def build_vocabulary(self, captions_list):\n        \n        for caption in captions_list:\n            tokens = self.tokenize(caption)\n            self.word_freq.update(tokens)\n        \n        for word, freq in self.word_freq.items():\n            if freq >= self.freq_threshold:\n                if word not in self.word2idx:\n                    self.word2idx[word] = self.idx\n                    self.idx2word[self.idx] = word\n                    self.idx += 1\n        \n        print(f\"Vocabulary built with {len(self.word2idx)} unique tokens\")\n        print(f\"Frequency threshold: {self.freq_threshold}\")\n    \n    @staticmethod\n    def tokenize(text):\n       \n        if text is None or pd.isna(text):\n            return []\n        \n        text = str(text).lower()\n        text = re.sub(r'[^a-z0-9\\s]', '', text)\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        return text.split()\n    \n    def encode(self, text):\n       \n        tokens = self.tokenize(text)\n        encoded = [self.word2idx[self.start_token]] \n        encoded += [self.word2idx.get(token, self.word2idx[self.unk_token]) for token in tokens]\n        encoded.append(self.word2idx[self.end_token])\n        return encoded\n    \n    def decode(self, indices):\n        \n        tokens = [self.idx2word.get(idx, self.unk_token) for idx in indices]\n        tokens = [t for t in tokens if t not in [self.pad_token, self.start_token, self.end_token]]\n        return ' '.join(tokens)\n    \n    def __len__(self):\n        return len(self.word2idx)\n\n\ndef load_and_preprocess_captions(captions_file, features_file):\n\n    df = pd.read_csv(captions_file)\n    print(f\"Loaded captions file with shape: {df.shape}\")\n    print(f\"Columns: {df.columns.tolist()}\")\n    \n    with open(features_file, 'rb') as f:\n        features_dict = pickle.load(f)\n    \n    available_images = set(features_dict.keys())\n    print(f\"Available image features: {len(available_images)}\")\n    \n    image_captions = {}\n    \n    image_col = 'image' if 'image' in df.columns else df.columns[0]\n    caption_col = 'caption' if 'caption' in df.columns else df.columns[1]\n    \n    skipped = 0\n    for idx, row in df.iterrows():\n        img_name = row[image_col]\n        caption = row[caption_col]\n        \n        if caption is None or pd.isna(caption):\n            skipped += 1\n            continue\n        \n        if img_name in available_images:\n            if img_name not in image_captions:\n                image_captions[img_name] = []\n            image_captions[img_name].append(str(caption))\n    \n    print(f\"Total images with captions: {len(image_captions)}\")\n    print(f\"Skipped {skipped} NaN captions\")\n    \n    return image_captions\n\n\ndef prepare_data(image_captions, vocab, train_split=0.8, val_split=0.1):\n    \n    all_images = list(image_captions.keys())\n    np.random.seed(42)  \n    np.random.shuffle(all_images)\n    \n    n_total = len(all_images)\n    n_train = int(n_total * train_split)\n    n_val = int(n_total * val_split)\n    \n    train_images = all_images[:n_train]\n    val_images = all_images[n_train:n_train + n_val]\n    test_images = all_images[n_train + n_val:]\n    \n    print(f\"\\nData split:\")\n    print(f\"  Train: {len(train_images)} images\")\n    print(f\"  Val:   {len(val_images)} images\")\n    print(f\"  Test:  {len(test_images)} images\")\n    \n    def create_dataset(image_list):\n        data = []\n        for img_name in image_list:\n            for caption in image_captions[img_name]:\n                encoded = vocab.encode(caption)\n                data.append((img_name, encoded, caption))\n        return data\n    \n    train_data = create_dataset(train_images)\n    val_data = create_dataset(val_images)\n    test_data = create_dataset(test_images)\n    \n    print(f\"\\nData instances:\")\n    print(f\"  Train: {len(train_data)} instances\")\n    print(f\"  Val:   {len(val_data)} instances\")\n    print(f\"  Test:  {len(test_data)} instances\")\n    \n    return train_data, val_data, test_data\n\n\ndef main():\n    CAPTIONS_FILE = find_captions_file()\n    FEATURES_FILE = '/kaggle/working/flickr30k_features.pkl'\n    \n    if CAPTIONS_FILE is None:\n        raise FileNotFoundError(\"Could not find captions.txt\")\n    \n    print(f\"Found captions at: {CAPTIONS_FILE}\")\n    \n    image_captions = load_and_preprocess_captions(CAPTIONS_FILE, FEATURES_FILE)\n    \n    all_captions = [cap for caps in image_captions.values() for cap in caps]\n    vocab = Vocabulary(freq_threshold=5)\n    vocab.build_vocabulary(all_captions)\n\n    train_data, val_data, test_data = prepare_data(image_captions, vocab)\n    \n    save_data = {\n        'vocab': vocab,\n        'train_data': train_data,\n        'val_data': val_data,\n        'test_data': test_data,\n        'image_captions': image_captions\n    }\n    \n    with open('/kaggle/working/preprocessed_data.pkl', 'wb') as f:\n        pickle.dump(save_data, f)\n    \n    print(f\"\\n✅ Preprocessed data saved to /kaggle/working/preprocessed_data.pkl\")\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"SAMPLE DATA:\")\n    print(\"=\" * 70)\n    sample_img, sample_encoded, sample_original = train_data[0]\n    print(f\"Image: {sample_img}\")\n    print(f\"Original caption: {sample_original}\")\n    print(f\"Encoded: {sample_encoded}\")\n    print(f\"Decoded: {vocab.decode(sample_encoded)}\")\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:08:52.792920Z","iopub.execute_input":"2026-02-15T11:08:52.793307Z","iopub.status.idle":"2026-02-15T11:09:02.808044Z","shell.execute_reply.started":"2026-02-15T11:08:52.793279Z","shell.execute_reply":"2026-02-15T11:09:02.807325Z"}},"outputs":[{"name":"stdout","text":"Found captions at: /kaggle/input/datasets/adityajn105/flickr30k/captions.txt\nLoaded captions file with shape: (158915, 2)\nColumns: ['image', 'caption']\nAvailable image features: 31783\nTotal images with captions: 31783\nSkipped 1 NaN captions\nVocabulary built with 7727 unique tokens\nFrequency threshold: 5\n\nData split:\n  Train: 25426 images\n  Val:   3178 images\n  Test:  3179 images\n\nData instances:\n  Train: 127129 instances\n  Val:   15890 instances\n  Test:  15895 instances\n\n✅ Preprocessed data saved to /kaggle/working/preprocessed_data.pkl\n\n======================================================================\nSAMPLE DATA:\n======================================================================\nImage: 3655176735.jpg\nOriginal caption:  AN older woman appears to read from a children 's book in an indoor setting , while a seated gentleman in a service uniform looks on .\nEncoded: [1, 73, 535, 156, 1182, 82, 341, 49, 31, 372, 125, 1428, 17, 73, 1756, 474, 14, 31, 657, 740, 17, 31, 2815, 254, 355, 52, 2]\nDecoded: an older woman appears to read from a children s book in an indoor setting while a seated gentleman in a service uniform looks on\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pickle\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n\nclass ImageCaptioningModel(nn.Module):\n    def __init__(self, vocab_size, feature_size=2048, embed_size=256, hidden_size=512, num_layers=1):\n        super(ImageCaptioningModel, self).__init__()\n        \n        self.vocab_size = vocab_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.feature_fc = nn.Linear(feature_size, hidden_size)\n        \n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        \n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n        \n        self.fc_out = nn.Linear(hidden_size, vocab_size)\n    \n    def forward(self, features, captions):\n        \n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        \n        cell = torch.zeros_like(hidden)\n        \n        embeddings = self.embedding(captions)\n        \n        lstm_out, _ = self.lstm(embeddings, (hidden, cell))\n        \n        outputs = self.fc_out(lstm_out)\n        \n        return outputs\n    \n    def generate_caption(self, features, start_token, end_token, max_len=20):\n        \n        batch_size = features.size(0)\n        device = features.device\n        \n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        cell = torch.zeros_like(hidden)\n        \n        inputs = torch.tensor([[start_token]] * batch_size, device=device)\n        \n        caption_ids = []\n        \n        for step in range(max_len):\n            embed = self.embedding(inputs)\n            lstm_out, (hidden, cell) = self.lstm(embed, (hidden, cell))\n            output = self.fc_out(lstm_out.squeeze(1))\n            \n            predicted = output.argmax(1)\n            caption_ids.append(predicted)\n            \n            if (predicted == end_token).all():\n                break\n            \n            inputs = predicted.unsqueeze(1)\n        \n        caption_ids = torch.stack(caption_ids, dim=1)\n        return caption_ids\n    \n    def beam_search(self, features, start_token, end_token, beam_width=3, max_len=20):\n       \n        device = features.device\n        \n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        cell = torch.zeros_like(hidden)\n        \n        sequences = [([start_token], 0.0, hidden.clone(), cell.clone())]\n        \n        for step in range(max_len):\n            all_candidates = []\n            \n            for seq, score, h, c in sequences:\n                if seq[-1] == end_token:\n                    all_candidates.append((seq, score, h, c))\n                    continue\n                \n                inp = torch.tensor([[seq[-1]]], device=device)\n                emb = self.embedding(inp)\n                \n                out, (new_h, new_c) = self.lstm(emb, (h, c))\n                logits = self.fc_out(out.squeeze(1))\n                \n                log_probs = torch.log_softmax(logits, dim=1)\n                top_log_probs, top_idx = log_probs.topk(beam_width, dim=1)\n                \n                for i in range(beam_width):\n                    token = top_idx[0][i].item()\n                    token_score = top_log_probs[0][i].item()\n                    \n                    candidate = (\n                        seq + [token],\n                        score + token_score,\n                        new_h.clone(),\n                        new_c.clone()\n                    )\n                    all_candidates.append(candidate)\n            \n            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n            \n            if all(seq[0][-1] == end_token for seq in sequences):\n                break\n        \n        best_seq = sequences[0][0]\n        return best_seq\n\n\nclass CaptionDataset(Dataset):\n    def __init__(self, data, features_dict, vocab):\n        self.data = data\n        self.features_dict = features_dict\n        self.vocab = vocab\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_name, caption_indices, _ = self.data[idx]\n        \n        features = self.features_dict[img_name]\n        features = torch.FloatTensor(features)\n        \n        caption = torch.LongTensor(caption_indices)\n        \n        return features, caption, img_name\n\n\ndef collate_fn(batch):\n    batch.sort(key=lambda x: len(x[1]), reverse=True)\n    \n    features, captions, img_names = zip(*batch)\n    \n    features = torch.stack(features, 0)\n    captions = pad_sequence(captions, batch_first=True, padding_value=0)\n    \n    return features, captions, img_names\n\n\nclass Trainer:\n    def __init__(self, model, train_loader, val_loader, vocab, device, config):\n        self.model = model.to(device)\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.vocab = vocab\n        self.device = device\n        self.config = config\n        \n        self.criterion = nn.CrossEntropyLoss(ignore_index=vocab.word2idx[vocab.pad_token])\n        \n        self.optimizer = optim.Adam(\n            model.parameters(),\n            lr=config['learning_rate'],\n            weight_decay=config.get('weight_decay', 0)\n        )\n        \n        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            self.optimizer,\n            mode='min',\n            factor=0.5,\n            patience=3\n        )\n        \n        self.train_losses = []\n        self.val_losses = []\n    \n    def train_epoch(self, epoch):\n        self.model.train()\n        total_loss = 0\n        \n        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1} [Train]\")\n        \n        for features, captions, _ in pbar:\n            features = features.to(self.device)\n            captions = captions.to(self.device)\n            \n            caption_input = captions[:, :-1]\n            caption_target = captions[:, 1:]\n            \n            outputs = self.model(features, caption_input)\n            \n            outputs = outputs.reshape(-1, outputs.size(2))\n            caption_target = caption_target.reshape(-1)\n            \n            loss = self.criterion(outputs, caption_target)\n            \n            self.optimizer.zero_grad()\n            loss.backward()\n            \n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=5.0)\n            \n            self.optimizer.step()\n            \n            total_loss += loss.item()\n            pbar.set_postfix({\"loss\": loss.item()})\n        \n        return total_loss / len(self.train_loader)\n    \n    def validate(self, epoch):\n        self.model.eval()\n        total_loss = 0\n        \n        with torch.no_grad():\n            pbar = tqdm(self.val_loader, desc=f\"Epoch {epoch+1} [Val]\")\n            \n            for features, captions, _ in pbar:\n                features = features.to(self.device)\n                captions = captions.to(self.device)\n                \n                caption_input = captions[:, :-1]\n                caption_target = captions[:, 1:]\n                \n                outputs = self.model(features, caption_input)\n                \n                outputs = outputs.reshape(-1, outputs.size(2))\n                caption_target = caption_target.reshape(-1)\n                \n                loss = self.criterion(outputs, caption_target)\n                \n                total_loss += loss.item()\n                pbar.set_postfix({\"loss\": loss.item()})\n        \n        return total_loss / len(self.val_loader)\n    \n    def train(self, num_epochs):\n        best_val_loss = float(\"inf\")\n        \n        for epoch in range(num_epochs):\n            train_loss = self.train_epoch(epoch)\n            val_loss = self.validate(epoch)\n            \n            self.train_losses.append(train_loss)\n            self.val_losses.append(val_loss)\n            \n            self.scheduler.step(val_loss)\n            \n            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n            print(f\"Train Loss: {train_loss:.4f}\")\n            print(f\"Val Loss:   {val_loss:.4f}\")\n            \n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                torch.save(self.model.state_dict(), \"/kaggle/working/best_model.pth\")\n                print(\"✅ Best model saved!\")\n            \n            print(\"-\" * 60)\n        \n        return self.train_losses, self.val_losses\n    \n    def plot_losses(self):\n        plt.figure(figsize=(10, 6))\n        plt.plot(self.train_losses, label=\"Train Loss\")\n        plt.plot(self.val_losses, label=\"Val Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.title(\"Training & Validation Loss\")\n        plt.legend()\n        plt.grid(True)\n        plt.savefig(\"/kaggle/working/loss_curve.png\", dpi=300)\n        plt.show()\n\ndef main():\n    print(\"Loading preprocessed data...\")\n    with open(\"/kaggle/working/preprocessed_data.pkl\", \"rb\") as f:\n        data = pickle.load(f)\n    \n    vocab = data[\"vocab\"]\n    train_data = data[\"train_data\"]\n    val_data = data[\"val_data\"]\n    \n    print(\"Loading image features...\")\n    with open(\"/kaggle/working/flickr30k_features.pkl\", \"rb\") as f:\n        features_dict = pickle.load(f)\n    \n    train_dataset = CaptionDataset(train_data, features_dict, vocab)\n    val_dataset = CaptionDataset(val_data, features_dict, vocab)\n    \n    config = {\n        \"batch_size\": 64,\n        \"learning_rate\": 0.001,\n        \"weight_decay\": 1e-5,\n        \"num_epochs\": 15,\n        \"embed_size\": 256,\n        \"hidden_size\": 512,\n        \"num_layers\": 1\n    }\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config[\"batch_size\"],\n        shuffle=True,\n        collate_fn=collate_fn,\n        num_workers=2\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config[\"batch_size\"],\n        shuffle=False,\n        collate_fn=collate_fn,\n        num_workers=2\n    )\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    model = ImageCaptioningModel(\n        vocab_size=len(vocab),\n        feature_size=2048,\n        embed_size=config[\"embed_size\"],\n        hidden_size=config[\"hidden_size\"],\n        num_layers=config[\"num_layers\"]\n    )\n    \n    print(\"\\nModel Summary:\")\n    print(f\"Vocabulary size: {len(vocab)}\")\n    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n    \n    trainer = Trainer(model, train_loader, val_loader, vocab, device, config)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"STARTING TRAINING\")\n    print(\"=\"*70 + \"\\n\")\n    \n    trainer.train(config[\"num_epochs\"])\n    trainer.plot_losses()\n    \n    print(\"\\n✅ TRAINING COMPLETE!\")\n    print(f\"✅ Best model saved to: /kaggle/working/best_model.pth\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:09:02.809272Z","iopub.execute_input":"2026-02-15T11:09:02.809609Z","iopub.status.idle":"2026-02-15T11:23:43.762203Z","shell.execute_reply.started":"2026-02-15T11:09:02.809585Z","shell.execute_reply":"2026-02-15T11:23:43.761498Z"}},"outputs":[{"name":"stdout","text":"Loading preprocessed data...\nLoading image features...\n\nModel Summary:\nVocabulary size: 7727\nTotal parameters: 8,568,111\n\n======================================================================\nSTARTING TRAINING\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [Train]: 100%|██████████| 1987/1987 [00:56<00:00, 34.95it/s, loss=2.98]\nEpoch 1 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.95it/s, loss=3.54] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/15\nTrain Loss: 3.6781\nVal Loss:   3.2240\n✅ Best model saved!\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.72it/s, loss=3.24]\nEpoch 2 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.92it/s, loss=3.36] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/15\nTrain Loss: 3.0394\nVal Loss:   3.0348\n✅ Best model saved!\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.55it/s, loss=2.78]\nEpoch 3 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.71it/s, loss=3.27] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/15\nTrain Loss: 2.8314\nVal Loss:   2.9669\n✅ Best model saved!\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [Train]: 100%|██████████| 1987/1987 [00:56<00:00, 35.43it/s, loss=2.81]\nEpoch 4 [Val]: 100%|██████████| 249/249 [00:02<00:00, 96.14it/s, loss=3.33] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/15\nTrain Loss: 2.6968\nVal Loss:   2.9332\n✅ Best model saved!\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [Train]: 100%|██████████| 1987/1987 [00:56<00:00, 35.45it/s, loss=2.56]\nEpoch 5 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.41it/s, loss=3.29] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/15\nTrain Loss: 2.5948\nVal Loss:   2.9245\n✅ Best model saved!\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.48it/s, loss=2.4] \nEpoch 6 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.59it/s, loss=3.19] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/15\nTrain Loss: 2.5130\nVal Loss:   2.9247\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.49it/s, loss=2.71]\nEpoch 7 [Val]: 100%|██████████| 249/249 [00:02<00:00, 96.23it/s, loss=3.37] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/15\nTrain Loss: 2.4447\nVal Loss:   2.9363\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.56it/s, loss=2.6] \nEpoch 8 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.73it/s, loss=3.24] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/15\nTrain Loss: 2.3853\nVal Loss:   2.9401\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.51it/s, loss=2.26]\nEpoch 9 [Val]: 100%|██████████| 249/249 [00:02<00:00, 96.46it/s, loss=3.41] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/15\nTrain Loss: 2.3331\nVal Loss:   2.9474\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.57it/s, loss=2.33]\nEpoch 10 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.68it/s, loss=3.31] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/15\nTrain Loss: 2.1708\nVal Loss:   2.9433\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.49it/s, loss=2.02]\nEpoch 11 [Val]: 100%|██████████| 249/249 [00:02<00:00, 96.81it/s, loss=3.36] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 11/15\nTrain Loss: 2.1199\nVal Loss:   2.9647\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 [Train]: 100%|██████████| 1987/1987 [00:55<00:00, 35.57it/s, loss=2.36]\nEpoch 12 [Val]: 100%|██████████| 249/249 [00:02<00:00, 96.13it/s, loss=3.4]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 12/15\nTrain Loss: 2.0822\nVal Loss:   2.9840\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13 [Train]: 100%|██████████| 1987/1987 [00:56<00:00, 35.47it/s, loss=1.75]\nEpoch 13 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.55it/s, loss=3.35] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 13/15\nTrain Loss: 2.0482\nVal Loss:   3.0043\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14 [Train]: 100%|██████████| 1987/1987 [00:56<00:00, 35.46it/s, loss=1.72]\nEpoch 14 [Val]: 100%|██████████| 249/249 [00:02<00:00, 95.46it/s, loss=3.47] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 14/15\nTrain Loss: 1.9423\nVal Loss:   3.0195\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15 [Train]: 100%|██████████| 1987/1987 [00:56<00:00, 35.45it/s, loss=2.01]\nEpoch 15 [Val]: 100%|██████████| 249/249 [00:02<00:00, 96.12it/s, loss=3.47] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15/15\nTrain Loss: 1.9134\nVal Loss:   3.0346\n------------------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n✅ TRAINING COMPLETE!\n✅ Best model saved to: /kaggle/working/best_model.pth\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport pickle\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nfrom collections import Counter\nfrom tqdm import tqdm\n\nimport torch.nn as nn\n\nclass ImageCaptioningModel(nn.Module):\n    def __init__(self, vocab_size, feature_size=2048, embed_size=256, hidden_size=512, num_layers=1):\n        super(ImageCaptioningModel, self).__init__()\n        \n        self.vocab_size = vocab_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.feature_fc = nn.Linear(feature_size, hidden_size)\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n        self.fc_out = nn.Linear(hidden_size, vocab_size)\n    \n    def forward(self, features, captions):\n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        cell = torch.zeros_like(hidden)\n        embeddings = self.embedding(captions)\n        lstm_out, _ = self.lstm(embeddings, (hidden, cell))\n        outputs = self.fc_out(lstm_out)\n        return outputs\n    \n    def generate_caption(self, features, start_token, end_token, max_len=20):\n\n        batch_size = features.size(0)\n        device = features.device\n        \n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        cell = torch.zeros_like(hidden)\n        \n        inputs = torch.tensor([[start_token]] * batch_size, device=device)\n        caption_ids = []\n        \n        for step in range(max_len):\n            embed = self.embedding(inputs)\n            lstm_out, (hidden, cell) = self.lstm(embed, (hidden, cell))\n            output = self.fc_out(lstm_out.squeeze(1))\n            \n            predicted = output.argmax(1)\n            caption_ids.append(predicted)\n            \n            if (predicted == end_token).all():\n                break\n            \n            inputs = predicted.unsqueeze(1)\n        \n        caption_ids = torch.stack(caption_ids, dim=1)\n        return caption_ids\n    \n    def beam_search(self, features, start_token, end_token, beam_width=3, max_len=20):\n     \n        device = features.device\n        \n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        cell = torch.zeros_like(hidden)\n        \n        sequences = [([start_token], 0.0, hidden.clone(), cell.clone())]\n        \n        for step in range(max_len):\n            all_candidates = []\n            \n            for seq, score, h, c in sequences:\n                if seq[-1] == end_token:\n                    all_candidates.append((seq, score, h, c))\n                    continue\n                \n                inp = torch.tensor([[seq[-1]]], device=device)\n                emb = self.embedding(inp)\n                out, (new_h, new_c) = self.lstm(emb, (h, c))\n                logits = self.fc_out(out.squeeze(1))\n                \n                log_probs = torch.log_softmax(logits, dim=1)\n                top_log_probs, top_idx = log_probs.topk(beam_width, dim=1)\n                \n                for i in range(beam_width):\n                    token = top_idx[0][i].item()\n                    token_score = top_log_probs[0][i].item()\n                    candidate = (\n                        seq + [token],\n                        score + token_score,\n                        new_h.clone(),\n                        new_c.clone()\n                    )\n                    all_candidates.append(candidate)\n            \n            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n            \n            if all(seq[0][-1] == end_token for seq in sequences):\n                break\n        \n        return sequences[0][0]\n\n\nclass CaptionGenerator:\n    def __init__(self, model_path, preprocessed_data_path, features_path, device=None):\n        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        print(\"Loading preprocessed data...\")\n        with open(preprocessed_data_path, 'rb') as f:\n            data = pickle.load(f)\n        \n        self.vocab = data['vocab']\n        self.test_data = data['test_data']\n        \n        print(\"Loading image features...\")\n        with open(features_path, 'rb') as f:\n            self.features_dict = pickle.load(f)\n        \n        print(\"Loading trained model...\")\n        self.model = ImageCaptioningModel(\n            vocab_size=len(self.vocab),\n            feature_size=2048,\n            embed_size=256,\n            hidden_size=512,\n            num_layers=1\n        )\n        \n        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n        self.model.to(self.device)\n        self.model.eval()\n        \n        print(f\"✓ Model loaded on {self.device}\")\n        print(f\"✓ Vocabulary size: {len(self.vocab)}\")\n        print(f\"✓ Test images: {len(set(img for img, _, _ in self.test_data))}\")\n    \n    def generate_caption_greedy(self, img_name):\n        if img_name not in self.features_dict:\n            return \"Image features not found\"\n        \n        features = torch.FloatTensor(self.features_dict[img_name]).unsqueeze(0).to(self.device)\n        \n        with torch.no_grad():\n            caption_ids = self.model.generate_caption(\n                features,\n                start_token=self.vocab.word2idx[self.vocab.start_token],\n                end_token=self.vocab.word2idx[self.vocab.end_token],\n                max_len=20\n            )\n        \n        caption_ids = caption_ids[0].cpu().numpy()\n        caption = self.vocab.decode(caption_ids)\n        \n        return caption\n    \n    def generate_caption_beam(self, img_name, beam_width=3):\n        if img_name not in self.features_dict:\n            return \"Image features not found\"\n        \n        features = torch.FloatTensor(self.features_dict[img_name]).unsqueeze(0).to(self.device)\n        \n        with torch.no_grad():\n            caption_ids = self.model.beam_search(\n                features,\n                start_token=self.vocab.word2idx[self.vocab.start_token],\n                end_token=self.vocab.word2idx[self.vocab.end_token],\n                beam_width=beam_width,\n                max_len=20\n            )\n        \n        caption = self.vocab.decode(caption_ids)\n        return caption\n    \n    def test_samples(self, num_samples=20, use_beam=False):\n        test_images = {}\n        for img_name, _, original_caption in self.test_data:\n            if img_name not in test_images:\n                test_images[img_name] = []\n            test_images[img_name].append(original_caption)\n        \n        image_names = list(test_images.keys())[:num_samples]\n        \n        print(\"\\n\" + \"=\"*80)\n        print(f\"Testing on {len(image_names)} images\")\n        print(f\"Method: {'Beam Search (width=3)' if use_beam else 'Greedy Search'}\")\n        print(\"=\"*80 + \"\\n\")\n        \n        for i, img_name in enumerate(image_names, 1):\n            print(f\"\\n[{i}/{len(image_names)}] Image: {img_name}\")\n            print(\"-\" * 80)\n            \n            if use_beam:\n                generated = self.generate_caption_beam(img_name, beam_width=3)\n            else:\n                generated = self.generate_caption_greedy(img_name)\n            \n            print(f\"Generated: {generated}\")\n            print(f\"\\nGround Truth:\")\n            for j, ref in enumerate(test_images[img_name][:3], 1):\n                print(f\"  {j}. {ref}\")\n    \n    def visualize_predictions(self, image_dir, num_examples=10, use_beam=False):\n        test_images = {}\n        for img_name, _, original_caption in self.test_data:\n            if img_name not in test_images:\n                test_images[img_name] = []\n            test_images[img_name].append(original_caption)\n        \n        image_names = list(test_images.keys())[:num_examples]\n        \n        num_cols = 2\n        num_rows = (num_examples + 1) // 2\n        \n        fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n        axes = axes.flatten() if num_examples > 1 else [axes]\n        \n        for idx, (img_name, ax) in enumerate(zip(image_names, axes)):\n            img_path = os.path.join(image_dir, img_name)\n            \n            if os.path.exists(img_path):\n                img = Image.open(img_path)\n                ax.imshow(img)\n            ax.axis('off')\n            \n            if use_beam:\n                generated = self.generate_caption_beam(img_name, beam_width=3)\n            else:\n                generated = self.generate_caption_greedy(img_name)\n            \n            title = f\"Generated: {generated}\\n\\nGround Truth:\\n\"\n            for i, ref in enumerate(test_images[img_name][:2], 1):\n                title += f\"{i}. {ref}\\n\"\n            \n            ax.set_title(title, fontsize=9, loc='left', wrap=True)\n        \n        for idx in range(len(image_names), len(axes)):\n            axes[idx].axis('off')\n        \n        plt.tight_layout()\n        \n        method = \"beam\" if use_beam else \"greedy\"\n        filename = f\"/kaggle/working/predictions_{method}.png\"\n        plt.savefig(filename, dpi=300, bbox_inches='tight')\n        plt.close()\n        \n        print(f\"\\n✓ Saved predictions to: {filename}\")\n    \n    def evaluate_diversity(self, num_samples=100):\n        test_images = {}\n        for img_name, _, _ in self.test_data:\n            if img_name not in test_images:\n                test_images[img_name] = True\n        \n        image_names = list(test_images.keys())[:num_samples]\n        \n        generated_captions = []\n        \n        print(f\"\\nGenerating captions for {len(image_names)} images to check diversity...\")\n        for img_name in tqdm(image_names):\n            caption = self.generate_caption_greedy(img_name)\n            generated_captions.append(caption)\n        \n        unique_captions = len(set(generated_captions))\n        caption_counter = Counter(generated_captions)\n        most_common = caption_counter.most_common(5)\n        \n        print(\"\\n\" + \"=\"*80)\n        print(\"DIVERSITY ANALYSIS\")\n        print(\"=\"*80)\n        print(f\"Total images tested: {len(image_names)}\")\n        print(f\"Unique captions generated: {unique_captions}\")\n        print(f\"Diversity ratio: {unique_captions/len(image_names)*100:.1f}%\")\n        print(f\"\\nMost common captions:\")\n        for caption, count in most_common:\n            print(f\"  [{count}x] {caption}\")\n        \n        if unique_captions < len(image_names) * 0.3:\n            print(\"\\n  WARNING: Low diversity detected!\")\n            print(\"   The model may still have issues generating varied captions.\")\n        else:\n            print(\"\\n Good diversity! Model is generating varied captions.\")\n\n\ndef main():\n    MODEL_PATH = \"/kaggle/working/best_model.pth\"\n    PREPROCESSED_DATA_PATH = \"/kaggle/working/preprocessed_data.pkl\"\n    FEATURES_PATH = \"/kaggle/working/flickr30k_features.pkl\"\n    IMAGE_DIR = \"/kaggle/input/datasets/adityajn105/flickr30k/Images\"\n    \n    image_dir_found = os.path.exists(IMAGE_DIR)\n    if not image_dir_found:\n        for root, dirs, files in os.walk(\"/kaggle/input\"):\n            if \"Images\" in dirs:\n                IMAGE_DIR = os.path.join(root, \"Images\")\n                image_dir_found = True\n                break\n    \n    generator = CaptionGenerator(\n        model_path=MODEL_PATH,\n        preprocessed_data_path=PREPROCESSED_DATA_PATH,\n        features_path=FEATURES_PATH\n    )\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"CHECKING CAPTION DIVERSITY\")\n    print(\"=\"*80)\n    generator.evaluate_diversity(num_samples=100)\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"GREEDY SEARCH RESULTS\")\n    print(\"=\"*80)\n    generator.test_samples(num_samples=15, use_beam=False)\n    \n    print(\"\\n\\n\" + \"=\"*80)\n    print(\"BEAM SEARCH RESULTS\")\n    print(\"=\"*80)\n    generator.test_samples(num_samples=15, use_beam=True)\n    \n    if image_dir_found:\n        print(\"\\n\" + \"=\"*80)\n        print(\"GENERATING VISUALIZATIONS\")\n        print(\"=\"*80)\n        print(f\"Using image directory: {IMAGE_DIR}\")\n        generator.visualize_predictions(IMAGE_DIR, num_examples=10, use_beam=False)\n        generator.visualize_predictions(IMAGE_DIR, num_examples=10, use_beam=True)\n    else:\n        print(\"\\n  Image directory not found. Skipping visualizations.\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\" EVALUATION COMPLETE!\")\n    print(\"=\"*80)\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:23:43.764048Z","iopub.execute_input":"2026-02-15T11:23:43.764356Z","iopub.status.idle":"2026-02-15T11:24:06.190157Z","shell.execute_reply.started":"2026-02-15T11:23:43.764326Z","shell.execute_reply":"2026-02-15T11:24:06.189494Z"}},"outputs":[{"name":"stdout","text":"Loading preprocessed data...\nLoading image features...\nLoading trained model...\n✓ Model loaded on cuda\n✓ Vocabulary size: 7727\n✓ Test images: 3179\n\n================================================================================\nCHECKING CAPTION DIVERSITY\n================================================================================\n\nGenerating captions for 100 images to check diversity...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [00:00<00:00, 142.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nDIVERSITY ANALYSIS\n================================================================================\nTotal images tested: 100\nUnique captions generated: 99\nDiversity ratio: 99.0%\n\nMost common captions:\n  [2x] a man in a red shirt is playing a guitar\n  [1x] a man in a yellow shirt and a woman in a yellow shirt are standing in front of a red\n  [1x] a group of people are standing on a dock near a lake\n  [1x] a man in a black jacket is standing on a sidewalk\n  [1x] a young girl in a pink shirt is sitting on a chair and playing with a toy\n\n Good diversity! Model is generating varied captions.\n\n================================================================================\nGREEDY SEARCH RESULTS\n================================================================================\n\n================================================================================\nTesting on 15 images\nMethod: Greedy Search\n================================================================================\n\n\n[1/15] Image: 463476205.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a yellow shirt and a woman in a yellow shirt are standing in front of a red\n\nGround Truth:\n  1.  A man on a motorcycle is riding in the street in the rain along with two green cabs and other vehicles .\n  2.  A motorcycle and two green taxis are driving down the street in the rain .\n  3.  There are many cars on a street during a rainy day .\n\n[2/15] Image: 52446935.jpg\n--------------------------------------------------------------------------------\nGenerated: a group of people are standing on a dock near a lake\n\nGround Truth:\n  1.  A group of people stand on a pier as the sun sets over the water .\n  2.  A number of people on a pier are silhouetted against the sunset .\n  3.  A group of men are standing on wooded pier as the sun sets .\n\n[3/15] Image: 3367399.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a black jacket is standing on a sidewalk\n\nGround Truth:\n  1.  A man in a jacket is standing in a gas station , next to a car and lights are shining in the distance .\n  2.  A man in a tan jacket at the gas station pumping gas .\n  3.  The man is filling his car with gasoline .\n\n[4/15] Image: 37969110.jpg\n--------------------------------------------------------------------------------\nGenerated: a young girl in a pink shirt is sitting on a chair and playing with a toy\n\nGround Truth:\n  1.  Brown-skinned girl pretends to do her homework while someone takes a picture for social services .\n  2.  A young girl writing on a piece of paper at a table .\n  3.  A young girl is sitting at a table writing .\n\n[5/15] Image: 2176364472.jpg\n--------------------------------------------------------------------------------\nGenerated: a man is standing on a platform and holding a leash\n\nGround Truth:\n  1.  The large , dark colored dog is doing a climbing stunt outdoors , while a man watches .\n  2.  A brown dog is running down a slope while a man follows beside him .\n  3.  A brown lab dog runs over an obstacle on a course .\n\n[6/15] Image: 4742677527.jpg\n--------------------------------------------------------------------------------\nGenerated: a man is standing in front of a food stand\n\nGround Truth:\n  1.  A man examines some meat hanging down a rope .\n  2.  A man reaching for a string of sausage links .\n  3.  A man is hanging sausages in a market .\n\n[7/15] Image: 458884858.jpg\n--------------------------------------------------------------------------------\nGenerated: a young girl in a pink shirt is sitting on a couch\n\nGround Truth:\n  1.  A lone , 2-3 year old blond child in a blue jacket is putting a small black plastic item in his mouth as he kneels on a waiting room couch pointed toward the back while looking at something or someone not in the room .\n  2.  A young boy in a blue jacket stands near a chair sucking on something .\n  3.  A blond child wearing a blue coat has a black cellphone in his mouth .\n\n[8/15] Image: 2513594933.jpg\n--------------------------------------------------------------------------------\nGenerated: a woman in a red dress is sitting on a bench with a man in a black shirt\n\nGround Truth:\n  1.  A woman in a red sundress walks past some stairs in front of a baroque building , where tourists are sitting .\n  2.  A lady in a sexy red dress walks in front of a crowd of men .\n  3.  Many people have decided to take a rest on the steps .\n\n[9/15] Image: 2973272684.jpg\n--------------------------------------------------------------------------------\nGenerated: two young girls are playing football\n\nGround Truth:\n  1.  A football player in a purple jersey is running the ball in for a touchdown .\n  2.  A football player runs across the field as the referee blows his whistle .\n  3.  A football player in a gold helmet is running with a football .\n\n[10/15] Image: 3399906919.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a green shirt is playing a game of chess\n\nGround Truth:\n  1.  A man and his female teammate watch his shot as they play a game of a beer pong .\n  2.  A man is throwing a small white ball at some red cups .\n  3.  A man trying to throw a ball into red cups .\n\n[11/15] Image: 2591573567.jpg\n--------------------------------------------------------------------------------\nGenerated: a woman in a blue swimming pool is doing a handstand in a pool\n\nGround Truth:\n  1.  A young swimmer with a yellow hairnet touching the wall .\n  2.  Two children in swim caps have a race in a pool .\n  3.  A girl in a yellow hat is swimming with a boy .\n\n[12/15] Image: 6840400032.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a green shirt is sitting on a chair in front of a crowd\n\nGround Truth:\n  1.  A group of string musicians collect money by playing on the street while people listen .\n  2.  Musicians are sitting down and playing their instruments outside while people watch .\n  3.  Musicians are playing their instruments for a crowd of onlookers .\n\n[13/15] Image: 2528521798.jpg\n--------------------------------------------------------------------------------\nGenerated: a race car is going through a turn\n\nGround Truth:\n  1.  A white rally car is throwing mud into the air as it approaches a bend in the track .\n  2.  A white race car splashes through a puddle on a dirt road\n  3.  A white race car makes a splash through a wet track .\n\n[14/15] Image: 5597473807.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a red shirt is playing a guitar\n\nGround Truth:\n  1.  A man with black and white face paint , wears a red hat as he sings into a microphone .\n  2.  A colorfully painted and dressed man performs for the audience .\n  3.  A singer is wearing a clown costume and makeup .\n\n[15/15] Image: 235183419.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a red shirt is playing a guitar\n\nGround Truth:\n  1.  Two men , 1 in yellow shirt , preparing to play in a high school band .\n  2.  A guitar-playing man kneels to adjust his equipment .\n  3.  The Bellingham High School band performing .\n\n\n================================================================================\nBEAM SEARCH RESULTS\n================================================================================\n\n================================================================================\nTesting on 15 images\nMethod: Beam Search (width=3)\n================================================================================\n\n\n[1/15] Image: 463476205.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a yellow shirt and a woman in a yellow shirt are standing in front of a red\n\nGround Truth:\n  1.  A man on a motorcycle is riding in the street in the rain along with two green cabs and other vehicles .\n  2.  A motorcycle and two green taxis are driving down the street in the rain .\n  3.  There are many cars on a street during a rainy day .\n\n[2/15] Image: 52446935.jpg\n--------------------------------------------------------------------------------\nGenerated: a group of people are standing on a dock near the water\n\nGround Truth:\n  1.  A group of people stand on a pier as the sun sets over the water .\n  2.  A number of people on a pier are silhouetted against the sunset .\n  3.  A group of men are standing on wooded pier as the sun sets .\n\n[3/15] Image: 3367399.jpg\n--------------------------------------------------------------------------------\nGenerated: a woman in a black jacket is standing on a sidewalk\n\nGround Truth:\n  1.  A man in a jacket is standing in a gas station , next to a car and lights are shining in the distance .\n  2.  A man in a tan jacket at the gas station pumping gas .\n  3.  The man is filling his car with gasoline .\n\n[4/15] Image: 37969110.jpg\n--------------------------------------------------------------------------------\nGenerated: a young girl in a pink shirt is sitting on a wooden floor playing a game\n\nGround Truth:\n  1.  Brown-skinned girl pretends to do her homework while someone takes a picture for social services .\n  2.  A young girl writing on a piece of paper at a table .\n  3.  A young girl is sitting at a table writing .\n\n[5/15] Image: 2176364472.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a blue shirt is standing on a platform\n\nGround Truth:\n  1.  The large , dark colored dog is doing a climbing stunt outdoors , while a man watches .\n  2.  A brown dog is running down a slope while a man follows beside him .\n  3.  A brown lab dog runs over an obstacle on a course .\n\n[6/15] Image: 4742677527.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a white shirt is standing in front of a food stand\n\nGround Truth:\n  1.  A man examines some meat hanging down a rope .\n  2.  A man reaching for a string of sausage links .\n  3.  A man is hanging sausages in a market .\n\n[7/15] Image: 458884858.jpg\n--------------------------------------------------------------------------------\nGenerated: a young girl is sitting in a car\n\nGround Truth:\n  1.  A lone , 2-3 year old blond child in a blue jacket is putting a small black plastic item in his mouth as he kneels on a waiting room couch pointed toward the back while looking at something or someone not in the room .\n  2.  A young boy in a blue jacket stands near a chair sucking on something .\n  3.  A blond child wearing a blue coat has a black cellphone in his mouth .\n\n[8/15] Image: 2513594933.jpg\n--------------------------------------------------------------------------------\nGenerated: a group of people are sitting on a sidewalk\n\nGround Truth:\n  1.  A woman in a red sundress walks past some stairs in front of a baroque building , where tourists are sitting .\n  2.  A lady in a sexy red dress walks in front of a crowd of men .\n  3.  Many people have decided to take a rest on the steps .\n\n[9/15] Image: 2973272684.jpg\n--------------------------------------------------------------------------------\nGenerated: two young girls are playing football\n\nGround Truth:\n  1.  A football player in a purple jersey is running the ball in for a touchdown .\n  2.  A football player runs across the field as the referee blows his whistle .\n  3.  A football player in a gold helmet is running with a football .\n\n[10/15] Image: 3399906919.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a green shirt is playing a game of chess\n\nGround Truth:\n  1.  A man and his female teammate watch his shot as they play a game of a beer pong .\n  2.  A man is throwing a small white ball at some red cups .\n  3.  A man trying to throw a ball into red cups .\n\n[11/15] Image: 2591573567.jpg\n--------------------------------------------------------------------------------\nGenerated: a woman wearing goggles and goggles is swimming in a pool\n\nGround Truth:\n  1.  A young swimmer with a yellow hairnet touching the wall .\n  2.  Two children in swim caps have a race in a pool .\n  3.  A girl in a yellow hat is swimming with a boy .\n\n[12/15] Image: 6840400032.jpg\n--------------------------------------------------------------------------------\nGenerated: a group of people are sitting on benches in a park\n\nGround Truth:\n  1.  A group of string musicians collect money by playing on the street while people listen .\n  2.  Musicians are sitting down and playing their instruments outside while people watch .\n  3.  Musicians are playing their instruments for a crowd of onlookers .\n\n[13/15] Image: 2528521798.jpg\n--------------------------------------------------------------------------------\nGenerated: a race car is going through the air\n\nGround Truth:\n  1.  A white rally car is throwing mud into the air as it approaches a bend in the track .\n  2.  A white race car splashes through a puddle on a dirt road\n  3.  A white race car makes a splash through a wet track .\n\n[14/15] Image: 5597473807.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a red shirt is singing into a microphone\n\nGround Truth:\n  1.  A man with black and white face paint , wears a red hat as he sings into a microphone .\n  2.  A colorfully painted and dressed man performs for the audience .\n  3.  A singer is wearing a clown costume and makeup .\n\n[15/15] Image: 235183419.jpg\n--------------------------------------------------------------------------------\nGenerated: a man in a red shirt is playing the guitar\n\nGround Truth:\n  1.  Two men , 1 in yellow shirt , preparing to play in a high school band .\n  2.  A guitar-playing man kneels to adjust his equipment .\n  3.  The Bellingham High School band performing .\n\n================================================================================\nGENERATING VISUALIZATIONS\n================================================================================\nUsing image directory: /kaggle/input/datasets/adityajn105/flickr30k/Images\n\n✓ Saved predictions to: /kaggle/working/predictions_greedy.png\n\n✓ Saved predictions to: /kaggle/working/predictions_beam.png\n\n================================================================================\n EVALUATION COMPLETE!\n================================================================================\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import gradio as gr\nimport torch\nimport torch.nn as nn\nimport pickle\nimport numpy as np\nfrom PIL import Image\nimport torchvision.transforms as transforms\nfrom torchvision import models\n\n\nclass ImageCaptioningModel(nn.Module):\n    def __init__(self, vocab_size, feature_size=2048, embed_size=256, hidden_size=512, num_layers=1):\n        super(ImageCaptioningModel, self).__init__()\n\n        self.vocab_size = vocab_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n\n        self.feature_fc = nn.Linear(feature_size, hidden_size)\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n        self.fc_out = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, features, captions):\n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        cell = torch.zeros_like(hidden)\n\n        embeddings = self.embedding(captions)\n        lstm_out, _ = self.lstm(embeddings, (hidden, cell))\n        outputs = self.fc_out(lstm_out)\n\n        return outputs\n\n    def generate_caption(self, features, start_token, end_token, max_len=20):\n        batch_size = features.size(0)\n        device = features.device\n\n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        cell = torch.zeros_like(hidden)\n\n        inputs = torch.tensor([[start_token]] * batch_size, device=device)\n        caption_ids = []\n\n        for step in range(max_len):\n            embed = self.embedding(inputs)\n            lstm_out, (hidden, cell) = self.lstm(embed, (hidden, cell))\n            output = self.fc_out(lstm_out.squeeze(1))\n\n            predicted = output.argmax(1)\n            caption_ids.append(predicted)\n\n            if (predicted == end_token).all():\n                break\n\n            inputs = predicted.unsqueeze(1)\n\n        caption_ids = torch.stack(caption_ids, dim=1)\n        return caption_ids\n\n    def beam_search(self, features, start_token, end_token, beam_width=3, max_len=20):\n        device = features.device\n\n        hidden = torch.tanh(self.feature_fc(features))\n        hidden = hidden.unsqueeze(0).repeat(self.num_layers, 1, 1)\n        cell = torch.zeros_like(hidden)\n\n        sequences = [([start_token], 0.0, hidden.clone(), cell.clone())]\n\n        for step in range(max_len):\n            all_candidates = []\n\n            for seq, score, h, c in sequences:\n                if seq[-1] == end_token:\n                    all_candidates.append((seq, score, h, c))\n                    continue\n\n                inp = torch.tensor([[seq[-1]]], device=device)\n                emb = self.embedding(inp)\n                out, (new_h, new_c) = self.lstm(emb, (h, c))\n                logits = self.fc_out(out.squeeze(1))\n\n                log_probs = torch.log_softmax(logits, dim=1)\n                top_log_probs, top_idx = log_probs.topk(beam_width, dim=1)\n\n                for i in range(beam_width):\n                    token = top_idx[0][i].item()\n                    token_score = top_log_probs[0][i].item()\n\n                    candidate = (\n                        seq + [token],\n                        score + token_score,\n                        new_h.clone(),\n                        new_c.clone()\n                    )\n                    all_candidates.append(candidate)\n\n            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n\n            if all(seq[0][-1] == end_token for seq in sequences):\n                break\n\n        return sequences[0][0]\n\n\nclass FeatureExtractor:\n    def __init__(self, device):\n        self.device = device\n\n        resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n        self.feature_extractor.to(device)\n        self.feature_extractor.eval()\n\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n        ])\n\n    def extract(self, image):\n        img_tensor = self.transform(image).unsqueeze(0).to(self.device)\n\n        with torch.no_grad():\n            features = self.feature_extractor(img_tensor)\n            features = features.view(features.size(0), -1)\n\n        return features\n\nclass CaptionGeneratorApp:\n    def __init__(self, model_path, preprocessed_data_path):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(f\"Using device: {self.device}\")\n\n        print(\"Loading vocabulary...\")\n        with open(preprocessed_data_path, 'rb') as f:\n            data = pickle.load(f)\n        self.vocab = data['vocab']\n\n        print(\"Loading caption model...\")\n        self.model = ImageCaptioningModel(\n            vocab_size=len(self.vocab),\n            feature_size=2048,\n            embed_size=256,\n            hidden_size=512,\n            num_layers=1\n        )\n\n        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n        self.model.to(self.device)\n        self.model.eval()\n\n        print(\"Loading feature extractor...\")\n        self.feature_extractor = FeatureExtractor(self.device)\n\n        print(\" App initialized successfully!\")\n\n    def generate_both_captions(self, image, beam_width=3):\n\n        if image is None:\n            return \"Please upload an image\", \"Please upload an image\"\n\n        try:\n            if not isinstance(image, Image.Image):\n                image = Image.fromarray(image).convert(\"RGB\")\n            else:\n                image = image.convert(\"RGB\")\n\n            # Extract features\n            features = self.feature_extractor.extract(image)\n\n            with torch.no_grad():\n                greedy_ids = self.model.generate_caption(\n                    features,\n                    start_token=self.vocab.word2idx[self.vocab.start_token],\n                    end_token=self.vocab.word2idx[self.vocab.end_token],\n                    max_len=20\n                )\n                greedy_ids = greedy_ids[0].cpu().numpy()\n                greedy_caption = self.vocab.decode(greedy_ids)\n\n            with torch.no_grad():\n                beam_ids = self.model.beam_search(\n                    features,\n                    start_token=self.vocab.word2idx[self.vocab.start_token],\n                    end_token=self.vocab.word2idx[self.vocab.end_token],\n                    beam_width=beam_width,\n                    max_len=20\n                )\n                beam_caption = self.vocab.decode(beam_ids)\n\n            return greedy_caption.capitalize() + \".\", beam_caption.capitalize() + \".\"\n\n        except Exception as e:\n            return f\"Error: {str(e)}\", f\"Error: {str(e)}\"\n\ndef create_gradio_interface():\n    MODEL_PATH = \"/kaggle/working/best_model.pth\"\n    PREPROCESSED_DATA_PATH = \"/kaggle/working/preprocessed_data.pkl\"\n\n    print(\"Initializing Caption Generator...\")\n    app = CaptionGeneratorApp(MODEL_PATH, PREPROCESSED_DATA_PATH)\n\n    with gr.Blocks(title=\"Image Caption Generator\", theme=gr.themes.Soft()) as demo:\n\n        gr.Markdown(\"Image Caption Generator\")\n        gr.Markdown(\"This app generates captions using **Greedy Search** and **Beam Search**.\")\n\n        with gr.Row():\n            with gr.Column(scale=1):\n                image_input = gr.Image(\n                    type=\"pil\",\n                    label=\"Upload Image\",\n                    height=400\n                )\n\n                beam_width = gr.Slider(\n                    minimum=2,\n                    maximum=5,\n                    value=3,\n                    step=1,\n                    label=\"Beam Width (Beam Search)\",\n                    info=\"Higher beam width = better caption but slower\"\n                )\n\n                with gr.Row():\n                    generate_btn = gr.Button(\"Generate Captions\", variant=\"primary\", size=\"lg\")\n                    clear_btn = gr.ClearButton([image_input], value=\"Clear\")\n\n            with gr.Column(scale=1):\n                greedy_output = gr.Textbox(\n                    label=\"Greedy Caption\",\n                    placeholder=\"Greedy caption will appear here...\",\n                    lines=3\n                )\n\n                beam_output = gr.Textbox(\n                    label=\"Beam Search Caption\",\n                    placeholder=\"Beam search caption will appear here...\",\n                    lines=3\n                )\n\n        generate_btn.click(\n            fn=app.generate_both_captions,\n            inputs=[image_input, beam_width],\n            outputs=[greedy_output, beam_output]\n        )\n\n        image_input.change(\n            fn=app.generate_both_captions,\n            inputs=[image_input, beam_width],\n            outputs=[greedy_output, beam_output]\n        )\n\n    return demo\n\n\ndef main():\n    print(\"=\" * 70)\n    print(\"STARTING GRADIO IMAGE CAPTION GENERATOR\")\n    print(\"=\" * 70)\n\n    demo = create_gradio_interface()\n\n    demo.launch(\n        share=True,\n        debug=True,\n        show_error=True\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T11:24:06.191033Z","iopub.execute_input":"2026-02-15T11:24:06.191393Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nSTARTING GRADIO IMAGE CAPTION GENERATOR\n======================================================================\nInitializing Caption Generator...\nUsing device: cuda\nLoading vocabulary...\nLoading caption model...\nLoading feature extractor...\n App initialized successfully!\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://12b79ff8cd7aa4a47a.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://12b79ff8cd7aa4a47a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":null}]}